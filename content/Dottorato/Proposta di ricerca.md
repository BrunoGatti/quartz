## Introduction
## Introduction

A long-term goal of Artificial Intelligence is to achieve a deeper semantic understanding of language. The research area involved in achieving this goal is Natural Language Understanding (NLU). Many NLU tasks focus on linking explicit knowledge to text, and one of those tasks is Semantic Parsing. Semantic Parsing's objective is to convert sentences into machine-readable representations of its underlying meaning, so that the dream of machines actually understanding human language may come true. Explicit semantics annotations have proven very useful in many tasks related but not limited to the NLU field: such explicit semantics annotations provide high-quality enrichment to training data that can be used to make machine learning models more accurate and robust and enhance Question Answering capabilities to understand and answer complex queries and, most of all, give NLP systems the potential to address many of its open problems.

Therefore, I propose a novel methodology for creating a large-scale multilingual Knowledge Base of semantically annotated phrases: a Knowledge Base that will be acquired by plain text through an automatic process, significantly mitigating costs of manual annotation and serving as a powerful resource for Semantic Parsing to facilitate more accurate language understanding across multiple languages. To create this resource, I plan to devise an innovative approach that extends Retrieval-Augmented Generation (RAG) integrated with methods based on syntax parsing, Word Sense Disambiguation (WSD), and Semantic Role Labeling (SRL). By combining these approaches, the Knowledge Base will capture nuanced meanings, relationships, and contexts, thus enhancing the richness and accuracy of the semantic annotations.

This will prove extremely useful not only to address the data paucity in the Semantic Parsing field, but also to unlock new capabilities of language models such as Natural Language Inference and reasoning. In the second part of my PHD I will focus on demonstrating the impact of this multilingual Knowledge Base when used to enhance neural network models for Semantic Parsing, and its utility in NLU applications such as machine translation and information extraction. This will achieve the overarching objective of overcoming current limitations in multilingual semantic representation and unlock the potential for machine reasoning, common sense, and truly universal language understanding.

## State of the art of the research field

Semantic Parsing has been tackled in many ways, leading to the development of many different formalisms, the most popular and used one being, arguably, the Abstract Meaning Representation (AMR) [1].
AMR models meaning using graphs where nodes are lemmas or disambiguated predicate senses and edges are semantic relationships between them.
The primary limitation of this approach lies in its inherent ambiguity and partial lack of full semantic representation, particularly regarding the lemmas. Although the predicate component of the representation is semantically explicit, it remains English-centric, as PropBank frames are exclusively in English.
Nonetheless efforts have been made in order to generalize AMR to other languages: AnCora for Spanish [2] or the Chinese PropBank[3], but they are not mutually interlinked, therefore, not really fit for a truly multilingual expansion of AMR. 
On the other side, against this trend, we find the work by Navigli et al. (2022)[4] who proposes the BabelNet Meaning Representation (BMR).
BMR is a language-independent meaning representation that replaces ambiguous nodes in the AMR representation with concepts that are generalized in term of language, therefore overcoming the AMR language specificity.
BMR, like AMR, abstracts the meaning in a Direct Acyclic graph (DAG), but while AMR relies on English lemmas and OntoNotes frames, BMR maps VerbAtlas [5] frames to PropBank and, instead of using Lemmas, uses BabelNet concepts which are multilingual and abstract.
This effort is very promising, however we need to point out that state of the art Semantic Parsing is executed through the use of pre-trained seq2seq models[6], but, BabelNet counts roughly 23,000,000 concepts, which means a prohibitive vocabulary size for a sequence to sequence model.
Additionally, both AMR and BMR suffer from data paucity, especially when multilingual coverage is a concern. Some important efforts have been recently made in that sense, with MOSAICo [7], which provides a semantically annotated dataset, including AMR annotation, in five languages.
MOSAICo utilizes documents collected from Wikipedia in English, French, German, Italian, and Spanish, sequentially applying the following automatic annotation steps: Word Sense Disambiguation (WSD), Semantic Role Labeling (SRL), and finally, Semantic Parsing. Essentially, MOSAICo is the first large-scale dataset of annotations for AMR in five languages.
However, for its semantic parsing task, MOSAICo translates the training corpora from English into foreign language phrases that are then mapped to English AMR. This approach not only perpetuates the previously mentioned issues but also results in semantic parsing that remains in English rather than the desired language.
This motivates my phd program in reaching the objectives that i will describe in the following session.

## Research objectives
To address the current limits of Semantic Parsing and representation, we propose developing a large scale multilingual Knowledge Base, reaching the following objectives:
1. A truly semantic parser: As of now, BMR is still not a reality; there is no parser available that can process text into a BMR representation. This means that the dream of a truly semantic parsing system remains unfulfilled. However, developing a large-scale multilingual knowledge base for semantic parsing will be a significant step toward achieving this goal. Such a resource would enable more comprehensive and accurate semantic representations across multiple languages, bringing us closer to realizing the vision of a fully semantic parsing system.
2. *Multilinguality and data paucity* in the Semantic Parsing task: data paucity is one of the main problems hindering progress in effective Semantic Parsing. The data is not only scarce in quantity but also in variety of domains. It has been shown, in fact, that state of the art semantic parsers suffer from performance issues when trained out of domain[8]. Implementing a large scale Knowledge Base of multilingual semantically annotated data would surely be beneficial to this cause. Especially if the methodology is fully automatic and is able to parse and annotate diverse documents. Similar considerations can be made for multilinguality, when Semantic Parsing is not restricted to English-only sentences performance tends to deteriorate, and this hinders the advancements towards a true semantic representation.
3. *Interlingua*: The above steps, if implemented correctly, will be a step forward in achieving a longed-for dream of Semantic Parsing, that is interlingual representation of meaning. This means that different phrases in different languages should have the same semantic representation. It should come to no surprise that the field that would benefit the most from this achievement would be machine translation, but this result would have effects on all subfields of NLP. The key advancement in this sense would also be the lesser need for a parallel corpora, this would unlock the capabilities of models to correctly understand the meaning of languages with fewer coverage.
4. Achieving and exploiting *Semantic grounding*: We envision the potential to achieve semantic grounding in machine responses. Our approach aims to capture nuanced meanings, relationships, and contexts across multiple languages through detailed semantic annotations. By associating small semantic graphs of explicit semantics with text, machines will be equipped to not only retrieve relevant information but also explain their answers by referencing specific entities, relationships, and contextual details. This would pave the way for transparent and justifiable responses, enhancing trust and reliability in AI systems. Additionally, utilizing this semantics would help justify and provide reliability to the answers, and ultimately, improve the knowledge base itself. The successful implementation of this approach will significantly advance the interpretability and accuracy of multilingual AI applications.

###  Methodology

In this section I will describe how I intend to tackle the generation of aforementioned Knowledge Base. There are two main approaches that need to be tested: create the Semantic Parsing starting from a syntactically annotated test or bypass the syntactic annotation step.
These two approaches will be fully automatic and won't need manual annotation. This is a strong desideratum in our case since the scope of this work is very large scale and manual annotation is prohibitively expensive.
The first step will be the data collection process.

#### Data collection
The data collection process will involve collecting plain text documents from various sources. Namely Wikipedia, Project Gutenberg, which is a large collection of free eBooks , PubMed Central which is a free digital archive of biomedical and life sciences, Common Crawl and many other. We will make sure to select data in various languages to prioritize multilingual annotations, in this sense datasets like Europarl and Open Subtitles. By utilizing these sources we can start the foundation for building a large legally compliant corpus of plain text documents for our multilingual Knowledge Base.

#### Annotation and aggregation process 

We will study the intersections of complex natural language understanding tasks, focusing on the inherent challenges these tasks present. The complexity arises from two main factors:

1. Scaling these multilingual tasks is not straightforward. For instance, performing Semantic Role Labeling (SRL) in languages other than English is not a trivial task. Each language presents unique challenges that require tailored approaches.
    
2. The output of these tasks is not necessarily compatible, and even when they are compatible, they can be inconsistent. For example, SRL produces a frame that describes the roles of various sentence components, while Word Sense Disambiguation (WSD) produces a synset that may not fit within that frame. This raises the question: how do we determine which output to use? Addressing this issue requires developing new techniques to link these disparate elements effectively.
    

To tackle these challenges, we will propose innovative techniques designed to resolve these inconsistencies and create a more integrated approach to multilingual natural language understanding.

We'll build upon models such as ESCHER, Multi-SRL (Conia and Navigli, 2020) for Semantic Role Labeling, and LeakDistill for Abstract Meaning Representation (AMR) Semantic Parsing. However, our aim is to advance these models to the next level, enhancing their capabilities and ensuring they work seamlessly together.

The outcome will be a corpus that, for the first time, is integrated across multiple semantic layers. This corpus will not only bridge the gap between different semantic tasks but also provide a unified framework for multilingual natural language understanding.

#### Leveraging RAG to bypass syntactic annotation
The aforementioned process will have trouble scaling, since it employs sequence to sequence language models like LeakDistill to perform Semantic Parsing. We could, instead, leverage an approach based on RAG (retrieved augmented generation) to generate the Knowledge Base starting from a relatively small quantity of annotated data. 
Leveraging Retrieval-Augmented Generation (RAG) to build a Knowledge Base involves an innovative approach that combines the strengths of retrieval and generation techniques for semantic annotation. By collecting and storing plain text documents in a structured format, we can perform initial parsing and annotation to identify linguistic components such as entities and relationships. These parsed texts are then converted into graph structures, where nodes represent entities and edges represent relationships, and stored in a graph database. When a new phrase or text segment needs annotation, the retrieval system searches for similar graph structures in the database using embeddings for similarity matching. Retrieved graphs are then analyzed and composed into a new graph that represents the semantic annotation for the input phrase, ensuring logical and semantic consistency. This generated annotation undergoes validation and, once confirmed, is integrated into the Knowledge Base. This method enables scalable, context-aware annotations and continuous improvement through a feedback loop, significantly enhancing the process of building and expanding a large-scale multilingual Knowledge Base.

## Expected Results and Impact

This project aims to develop a large-scale multilingual Knowledge Base with semantically annotated phrases, leveraging both classical methods and innovative approaches like Retrieval-Augmented Generation (RAG). By integrating syntax parsing, Word Sense Disambiguation (WSD), and Semantic Role Labeling (SRL) alongside RAG, we anticipate creating a resource that addresses the current data paucity in Semantic Parsing and enhances the richness and accuracy of annotations. This Knowledge Base is expected to significantly improve Natural Language Understanding (NLU) by facilitating more accurate language understanding across multiple languages, enabling natural language inference, and reasoning capabilities. The successful implementation of this project could have a profound impact on the field of NLU by overcoming current limitations in multilingual semantic representation, achieving interlingual representation of meaning, and advancing machine reasoning and comprehension grounding. This would not only enhance machine translation and information extraction but also lead to more transparent, trustworthy, and reliable AI systems, ultimately pushing the boundaries of universal language understanding.

## Bibliografia

1. Laura Banarescu, Claire Bonial, Shu Cai, Madalina Georgescu, Kira Griffitt, Ulf Hermjakob, Kevin Knight, Philipp Koehn, Martha Palmer, and Nathan Schneider. Abstract Meaning Representation for sembanking. In Proceedings of the 7th Linguistic Annotation Workshop and Interoperability with Discourse, pages 178–186, Sofia, Bulgaria, August 2013. Association for Computational Linguistics. [URL:](https://aclanthology.org/ W13-2322).
2. Eduard Hovy, Mitchell Marcus, Martha Palmer, Lance Ramshaw, and Ralph Weischedel. 2006. OntoNotes: The 90% Solution. In Proceedings of the Human Language Technology Conference of the NAACL, Companion Volume: Short Papers, pages 57–60, New York City, USA. Association for Computational Linguistics.
3. Nianwen Xue, Ondˇrej Bojar, Jan Hajic, Martha Palmer, ˇ Zdenka Urešová, and Xiuhong Zhang. 2014. ˇ Not an Interlingua, But Close: Comparison of English AMRs to Chinese and Czech. In Proceedings of the Ninth International Conference on Language Resources and Evaluation (LREC’14), pages 1765– 1772, Reykjavik, Iceland. European Language Resources Association (ELRA).
4. Abelardo Carlos Martínez Lorenzo, Marco Maru , and Roberto Navigli. 2022. Fully-Semantic Parsing and Genreation: the BabelNet Meaning Representation.
5. Andrea Di Fabio, Simone Conia, and Roberto Navigli. 2019. VerbAtlas: a Novel Large-Scale Verbal Semantic Resource and Its Application to Semantic Role Labeling. In Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP), pages 627–637, Hong Kong, China. Association for Computational Linguistics.
6. Mike Lewis, Yinhan Liu, Naman Goyal, Marjan Ghazvininejad, Abdelrahman Mohamed, Omer Levy, Veselin Stoyanov, and Luke Zettlemoyer. BART: Denoising sequence-to-sequence pre-training for natural language generation, translation, and comprehension. In Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, pages 7871–7880, Online, July 2020. Association for Computational Linguistics. URL: https://aclanthology.org/2020.acl-main.703, doi:10.18653/ v1/2020.acl-main.703.
7. Simone Conia, Edoardo Bardba, Abelardo Carlos Martìnex Lorenzo, Pere-Lluìs Huguet Cabot, Riccardo Orlando, Luigi Procopio, Roberto Navigli. A multilingual Open-text Semantically Annotated Interlinked Corpus. 2024.
8. Michele Bevilacqua, Rexhina Blloshmi, and Roberto Navigli. One spring to rule them both: Symmetric amr semantic parsing and generation without a complex pipeline. Proceedings of the AAAI Conference on Artificial Intelligence, 35(14):12564–12573, May 2021. URL: https://ojs.aaai.org/ index.php/AAAI/article/view/17489.
9. Edoardo Barba, Tommaso Pasini, and Roberto Navigli. 2021. ESC: Redesigning WSD with extractive sense comprehension. In Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, pages 4661–4672, Online. Association for Computational Linguistics.
   